<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2018-01-22 Mon 15:36 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Artificial Intelligence</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Jethro Kuan" />
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.js"></script>
<script type="text/javascript" src="http://www.pirilampo.org/styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Artificial Intelligence</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org533ec48">1. What is Artificial Intelligence?</a>
<ul>
<li><a href="#orgff545a6">1.1. Acting Humanly: Turing Test</a></li>
<li><a href="#orgb881d00">1.2. Thinking Humanly</a></li>
<li><a href="#orgeda76f3">1.3. Thinking rationally</a></li>
<li><a href="#org98014e8">1.4. Acting Rationally</a></li>
</ul>
</li>
<li><a href="#orgf0d683d">2. Intelligent Agents</a>
<ul>
<li><a href="#orge8126a0">2.1. Rational Agents</a></li>
<li><a href="#orgedfdac7">2.2. Exploration vs Exploitation</a></li>
<li><a href="#org46d5020">2.3. Specifying Task Environment (PEAS)</a></li>
<li><a href="#orgc42c669">2.4. Properties of Task Environments</a></li>
<li><a href="#org1312789">2.5. Table-Driven Agent</a></li>
<li><a href="#org105b037">2.6. Reflex agents</a></li>
<li><a href="#org0808ddb">2.7. Model-based Reflex Agents</a></li>
<li><a href="#orgd47e249">2.8. Goal-based agents</a></li>
<li><a href="#orgda9b055">2.9. Utility-based agents</a></li>
<li><a href="#orgf2d2103">2.10. Learning agents</a></li>
<li><a href="#org76ab81e">2.11. State representations</a>
<ul>
<li><a href="#org2d9803d">2.11.1. Atomic Representation</a></li>
<li><a href="#org68d347c">2.11.2. Factored Representation</a></li>
<li><a href="#org1ee377e">2.11.3. Structured Representations</a></li>
<li><a href="#orga6daf98">2.11.4. Implications</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org9c2be81">3. Problem-Solving</a>
<ul>
<li><a href="#orgc9f2f8b">3.1. Searching for Solutions</a>
<ul>
<li><a href="#orgf79408e">3.1.1. How Search Algorithms Work</a></li>
<li><a href="#org5669856">3.1.2. Measuring Performance</a></li>
<li><a href="#orgef5a053">3.1.3. Uninformed Search Strategies</a>
<ul>
<li><a href="#org98adbfe">3.1.3.1. Breadth-first Search</a></li>
<li><a href="#org57e65cc">3.1.3.2. Uniform-cost Search</a></li>
<li><a href="#org39629c8">3.1.3.3. Depth-first Search</a></li>
<li><a href="#org8cbb4d2">3.1.3.4. Depth-limited Search</a></li>
<li><a href="#org2366c86">3.1.3.5. Iterative Deepening Depth-first Search</a></li>
<li><a href="#orgfd81acf">3.1.3.6. Bidirectional Search</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<p>
-<b>- mode: Org; org-download-image-dir: "./images/ai/"; -</b>-
</p>
<div id="outline-container-org533ec48" class="outline-2">
<h2 id="org533ec48"><span class="section-number-2">1</span> What is Artificial Intelligence?</h2>
<div class="outline-text-2" id="text-1">
<p>
Designing agents that act rationally (e.g. through maximising a reward
function).
</p>

<p>
Humans often act in ways that do not maximise their own benefit
(irrational).
</p>
</div>
<div id="outline-container-orgff545a6" class="outline-3">
<h3 id="orgff545a6"><span class="section-number-3">1.1</span> Acting Humanly: Turing Test</h3>
<div class="outline-text-3" id="text-1-1">
<p>
A computer would require:
</p>

<ul class="org-ul">
<li>natural language processing</li>
<li>knowledge representation</li>
<li>automated reasoning</li>
<li>machine learning</li>
</ul>
</div>
</div>
<div id="outline-container-orgb881d00" class="outline-3">
<h3 id="orgb881d00"><span class="section-number-3">1.2</span> Thinking Humanly</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Cognitive science brings together computer models and experimental
techniques in psychology to construct testable and provable theories
of the human mind.
</p>
</div>
</div>
<div id="outline-container-orgeda76f3" class="outline-3">
<h3 id="orgeda76f3"><span class="section-number-3">1.3</span> Thinking rationally</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Taking informal knowledge and expressing it in logical terms.
</p>
</div>
</div>
<div id="outline-container-org98014e8" class="outline-3">
<h3 id="org98014e8"><span class="section-number-3">1.4</span> Acting Rationally</h3>
<div class="outline-text-3" id="text-1-4">
<p>
A rational agent is one that acts so as to achieve the best outcome
or,when there is uncertainty, the best expected outcome.
</p>

<p>
An agent is a function from percept histories to actions, i.e. \(f: P^*
\rightarrow A\). We seek the best-performing agent for a certain task;
must consider computation limits.
</p>
</div>
</div>
</div>
<div id="outline-container-orgf0d683d" class="outline-2">
<h2 id="orgf0d683d"><span class="section-number-2">2</span> Intelligent Agents</h2>
<div class="outline-text-2" id="text-2">
<ul class="org-ul">
<li>Agents perceive the environment through sensors</li>
<li>Agents act upon the environment through actuators</li>
</ul>
</div>
<div id="outline-container-orge8126a0" class="outline-3">
<h3 id="orge8126a0"><span class="section-number-3">2.1</span> Rational Agents</h3>
<div class="outline-text-3" id="text-2-1">
<ul class="org-ul">
<li>For each possible percept sequence, select an action that is
expected to maximise its performance measure. The performance
measure is a function of a given sequence of environment states.</li>
<li>Given the evidence provided by the percept sequence and whatever
built-in knowledge the agent has.</li>
<li>Agents can perform actions that help them gather useful information
(exploration)</li>
<li>An agent is <i>autonomous</i> if its behaviour is determined by its own
experience (with ability to learn and adapt)</li>
</ul>
</div>
</div>
<div id="outline-container-orgedfdac7" class="outline-3">
<h3 id="orgedfdac7"><span class="section-number-3">2.2</span> Exploration vs Exploitation</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Doing actions that modify future percepts (information gathering) is
an important part of rationality. In most scenarios, agents don't know
the entire environment <i>a priori</i>.
</p>
</div>
</div>
<div id="outline-container-org46d5020" class="outline-3">
<h3 id="org46d5020"><span class="section-number-3">2.3</span> Specifying Task Environment (PEAS)</h3>
<div class="outline-text-3" id="text-2-3">
<ul class="org-ul">
<li>Performance measure</li>
<li>Environment</li>
<li>Actuators</li>
<li>Sensors</li>
</ul>
</div>
</div>
<div id="outline-container-orgc42c669" class="outline-3">
<h3 id="orgc42c669"><span class="section-number-3">2.4</span> Properties of Task Environments</h3>
<div class="outline-text-3" id="text-2-4">
<dl class="org-dl">
<dt>Fully observable</dt><dd>whether an agent's sensors gives it access to
the complete state of the environment at any given point in time</dd>
<dt>Deterministic</dt><dd>if the next state is completely determined by the
current environment. Otherwise it is <b>stochastic</b>.</dd>
<dt>Episodic</dt><dd>whether an agents experience is divided into atomic
episodes. In each episode, an agent receives a percept
and performs a single action. In <b>sequential</b>
environments short-term actions can have long-term
consequences. For this reason, episodic environments are
generally simpler.</dd>
<dt>Static</dt><dd>whether the environment can change while the agent is
deliberating.</dd>
<dt>Discrete</dt><dd>whether the state of the environment, how time is
handled, and the percepts and actions of the agent
discretely quantized.</dd>
<dt>Single agent</dt><dd>in some environments, for example chess, there are
multiple agents acting in the same environment.
<dl class="org-dl">
<dt>cooperative</dt><dd>if the two agents need to work together.</dd>
<dt>competitive</dt><dd>if the two agents are working against each other.</dd>
</dl></dd>
<dt>Known</dt><dd>whether the agent knows the outcome of its actions.</dd>
</dl>
</div>
</div>
<div id="outline-container-org1312789" class="outline-3">
<h3 id="org1312789"><span class="section-number-3">2.5</span> Table-Driven Agent</h3>
<div class="outline-text-3" id="text-2-5">
<p>
Simple to implement, and works. However, the number of table entries
is exponential in time: \(\text{#percepts}^\text{time}\). Hence it is
doomed to failure. The key challenge to AI is to produce rational
behaviour from a small program rather than a vast table.
</p>
</div>
</div>
<div id="outline-container-org105b037" class="outline-3">
<h3 id="org105b037"><span class="section-number-3">2.6</span> Reflex agents</h3>
<div class="outline-text-3" id="text-2-6">
<p>
A simple reflex agent is one that selects actions on the basis of the
<i>current</i> percept, ignoring the rest of the percept history. A
<i>condition-action</i> rule is triggered upon processing the current
percept. E.g. <b>if</b> the car in front is braking, <b>then</b> brake too.
</p>

<p>
Basing actions on only the current percept can be highly limiting, and
can also lead to infinite loops. Randomized actions of the right kind
can help escape these infinite loops.
</p>
</div>
</div>
<div id="outline-container-org0808ddb" class="outline-3">
<h3 id="org0808ddb"><span class="section-number-3">2.7</span> Model-based Reflex Agents</h3>
<div class="outline-text-3" id="text-2-7">
<p>
The agent maintains some <b>internal state</b> that depends on percept
history and reflects at least some of the unobserved aspects of the
current state. Information about how the world evolves independently
from the agent is encoded into the agent. This knowledge is called a
<b>model</b> of the world, and this agent is hence a <b>model-based</b> agent.
</p>
</div>
</div>
<div id="outline-container-orgd47e249" class="outline-3">
<h3 id="orgd47e249"><span class="section-number-3">2.8</span> Goal-based agents</h3>
<div class="outline-text-3" id="text-2-8">
<p>
Knowing about the current state of the environment may not be enough
to decide on what to do. Agents may need <b>goal</b> information that
describes situations that are desirable. Sometimes goal-based action
selection is straightforward, but in others <b>searching</b> and <b>planning</b>
are required to achieve the goal. Goal-based agents are flexible
because the knowledge that supports its decisions is represented
explicitly and can be modified, although it is less efficient.
</p>
</div>
</div>
<div id="outline-container-orgda9b055" class="outline-3">
<h3 id="orgda9b055"><span class="section-number-3">2.9</span> Utility-based agents</h3>
<div class="outline-text-3" id="text-2-9">
<p>
Goals provide a binary distinction between good and bad states. A more
general performance measure should allow a comparison between world
states according to exactly how good it is to the agent. An agent's
<b>utility function</b> is an internalisation of the performance measure.
An agent chooses actions to maximise its expected utility. A
utility-based agents has to model and keep track of its environment.
</p>
</div>
</div>
<div id="outline-container-orgf2d2103" class="outline-3">
<h3 id="orgf2d2103"><span class="section-number-3">2.10</span> Learning agents</h3>
<div class="outline-text-3" id="text-2-10">
<p>
A learning agent can be divided into four conceptual components.
</p>
<dl class="org-dl">
<dt>learning element</dt><dd>responsible for making improvements</dd>
<dt>performance element</dt><dd>responsible for selecting extrenal actions</dd>
<dt>problem generator</dt><dd>suggests actions that will lead to new and
informative experiences</dd>
</dl>

<p>
the learning element takes in feedback from the <b>critic</b> on how the
agent is doing and determines show the performance element should be
modified to do better in the future.
</p>
</div>
</div>
<div id="outline-container-org76ab81e" class="outline-3">
<h3 id="org76ab81e"><span class="section-number-3">2.11</span> State representations</h3>
<div class="outline-text-3" id="text-2-11">
</div>
<div id="outline-container-org2d9803d" class="outline-4">
<h4 id="org2d9803d"><span class="section-number-4">2.11.1</span> Atomic Representation</h4>
<div class="outline-text-4" id="text-2-11-1">
<p>
In an atomic representation each state of the world is indivisible,
and has no internal structure. Search, game-playing, hidden Markov
models and Markov decision processes all work with atomic
representations.
</p>
</div>
</div>
<div id="outline-container-org68d347c" class="outline-4">
<h4 id="org68d347c"><span class="section-number-4">2.11.2</span> Factored Representation</h4>
<div class="outline-text-4" id="text-2-11-2">
<p>
A factored representation splits up each state into a fixed set of
<b>variables</b> or <b>attributes</b>, each of which can have a <b>value</b>.
</p>

<p>
Constraint satisfaction algorithms, propositional logic, planning,
Bayesian networks and machine learning algorithms work with factored
representations.
</p>
</div>
</div>

<div id="outline-container-org1ee377e" class="outline-4">
<h4 id="org1ee377e"><span class="section-number-4">2.11.3</span> Structured Representations</h4>
<div class="outline-text-4" id="text-2-11-3">
<p>
Structured representations underlie relational databases and
first-order logic, first-order probability models, knowledge-based
learning and much of natural language understanding.
</p>
</div>
</div>
<div id="outline-container-orga6daf98" class="outline-4">
<h4 id="orga6daf98"><span class="section-number-4">2.11.4</span> Implications</h4>
<div class="outline-text-4" id="text-2-11-4">
<p>
A more expressive representation can capture, at least as concisely, a
everything a more expressive one can capture, plus more. On the other
hand, reasoning and learning become more complex as the expressive
power of the representation increases.
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org9c2be81" class="outline-2">
<h2 id="org9c2be81"><span class="section-number-2">3</span> Problem-Solving</h2>
<div class="outline-text-2" id="text-3">
<p>
Problem-solving agents use <i>atomic</i> representations, as compared to
goal-based agents, which use more advanced factored or structured
representations.
</p>

<p>
The process of looking for a sequence of actions that reaches the goal
is called <i>search</i>. A search algorithm takes a problem as input and
returns a <i>solution</i> in the form of an action sequence.
</p>
</div>
<div id="outline-container-orgc9f2f8b" class="outline-3">
<h3 id="orgc9f2f8b"><span class="section-number-3">3.1</span> Searching for Solutions</h3>
<div class="outline-text-3" id="text-3-1">
</div>
<div id="outline-container-orgf79408e" class="outline-4">
<h4 id="orgf79408e"><span class="section-number-4">3.1.1</span> How Search Algorithms Work</h4>
<div class="outline-text-4" id="text-3-1-1">
<p>
Search algorithms consider various possible action sequences. The
possible action sequences start at the initial state form a <i>search
tree</i>.
</p>

<p>
Search algorithms require a data structure to keep track of the search
tree that is being constructed.
</p>

<dl class="org-dl">
<dt>state</dt><dd>state in the state space to which the node corresponds</dd>
<dt>parent</dt><dd>the node in the search tree that generated this node</dd>
<dt>action</dt><dd>the action that was applied to the parent to generate this node</dd>
<dt>path-cost</dt><dd>the cost, traditionally denoted by \(g(n)\), of the path
from the initial state to the node, as indicated by the
parent pointers</dd>
</dl>
</div>
</div>
<div id="outline-container-org5669856" class="outline-4">
<h4 id="org5669856"><span class="section-number-4">3.1.2</span> Measuring Performance</h4>
<div class="outline-text-4" id="text-3-1-2">
<dl class="org-dl">
<dt>completeness</dt><dd>is the algorithm guaranteed to find a solution if
it exists?</dd>
<dt>optimality</dt><dd>does the strategy find the optimal solution?</dd>
<dt>time complexity</dt><dd>how long does it take to find a solution?</dd>
<dt>space complexity</dt><dd>how much memory is required to do the search?</dd>
</dl>
</div>
</div>
<div id="outline-container-orgef5a053" class="outline-4">
<h4 id="orgef5a053"><span class="section-number-4">3.1.3</span> Uninformed Search Strategies</h4>
<div class="outline-text-4" id="text-3-1-3">
</div>
<div id="outline-container-org98adbfe" class="outline-5">
<h5 id="org98adbfe"><span class="section-number-5">3.1.3.1</span> Breadth-first Search</h5>
<div class="outline-text-5" id="text-3-1-3-1">
<p>
The root node is expanded first, then all the successors of the root
node are expanded next, then their successors, and so on.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">performance</th>
<th scope="col" class="org-left">rating</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">completeness</td>
<td class="org-left">YES</td>
</tr>

<tr>
<td class="org-left">optimal</td>
<td class="org-left">NO</td>
</tr>

<tr>
<td class="org-left">time complexity</td>
<td class="org-left">\(O(b^d)\)</td>
</tr>

<tr>
<td class="org-left">space complexity</td>
<td class="org-left">\(O(b^d)\)</td>
</tr>
</tbody>
</table>

<p>
The shallowest node may not be the most optimal node.
</p>

<p>
The space used in the <i>explored set</i> is \(O(b^{d-1})\) and the space
used in the <i>frontier</i> is \(O(b^d)\).
</p>

<p>
In general, exponential-complexity search problems cannot be solved by
uninformed methods for any but the smallest instances.
</p>
</div>
</div>
<div id="outline-container-org57e65cc" class="outline-5">
<h5 id="org57e65cc"><span class="section-number-5">3.1.3.2</span> Uniform-cost Search</h5>
<div class="outline-text-5" id="text-3-1-3-2">
<p>
Uniform-cost search expands the node \(n\) with the lowest path
cost \(g(n)\). The goal test is applied to a node when it is selected
for expansion rather than when it is first generated.
</p>

<p>
This is equivalent to BFS if all step costs are qual.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">performance</th>
<th scope="col" class="org-left">rating</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">completeness</td>
<td class="org-left">MAYBE</td>
</tr>

<tr>
<td class="org-left">optimal</td>
<td class="org-left">YES</td>
</tr>

<tr>
<td class="org-left">time</td>
<td class="org-left">\(O(b^{1+\lfloor{\frac{C^*}{\epsilon}}\rfloor})\), where \(C^*\) is the optimal cost.</td>
</tr>

<tr>
<td class="org-left">space</td>
<td class="org-left">\(O(b^{1+\lfloor{\frac{C^*}{\epsilon}}\rfloor})\)</td>
</tr>
</tbody>
</table>

<p>
Completeness is guaranteed only if the cost of every step exceeds some
small positive constant \(\epsilon\). an infinite loop may occur if
there is a path with an infinite sequence of zero-cost actions.
</p>
</div>
</div>
<div id="outline-container-org39629c8" class="outline-5">
<h5 id="org39629c8"><span class="section-number-5">3.1.3.3</span> Depth-first Search</h5>
<div class="outline-text-5" id="text-3-1-3-3">
<p>
Always expands the <i>deepest</i> node in the current frontier of the
search tree.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">performance</th>
<th scope="col" class="org-left">rating</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">completeness</td>
<td class="org-left">YES</td>
</tr>

<tr>
<td class="org-left">optimal</td>
<td class="org-left">NO</td>
</tr>

<tr>
<td class="org-left">time complexity</td>
<td class="org-left">\(O(b^m)\)</td>
</tr>

<tr>
<td class="org-left">space complexity</td>
<td class="org-left">\(O(b^m)\), \(O(m)\) if backtrack</td>
</tr>
</tbody>
</table>

<p>
The time complexity of DFS may be worse than BFS: \(O(b^m)\) might be
larger than \(O(b^d)\).
</p>

<p>
DFS only requires storage of \(O(bm)\) nodes, where \(m\) is the maximum
depth of any node. <b>backtracking search</b> only generates one successor
at a time, modifying the current state description rather than copying
it. Memory requirements reduce to one state description and \(O(m)\)
actions.
</p>
</div>
</div>
<div id="outline-container-org8cbb4d2" class="outline-5">
<h5 id="org8cbb4d2"><span class="section-number-5">3.1.3.4</span> Depth-limited Search</h5>
<div class="outline-text-5" id="text-3-1-3-4">
<p>
In depth-limited search, nodes at depth of pre-determined limit \(l\)
are treated as if they had no successors. This limit solves the
infinite-path problem.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">performance</th>
<th scope="col" class="org-left">rating</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">completeness</td>
<td class="org-left">YES</td>
</tr>

<tr>
<td class="org-left">optimal</td>
<td class="org-left">NO</td>
</tr>

<tr>
<td class="org-left">time complexity</td>
<td class="org-left">\(O(b^l)\)</td>
</tr>

<tr>
<td class="org-left">space complexity</td>
<td class="org-left">\(O(b^l)\), \(O(l)\) if backtrack</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-org2366c86" class="outline-5">
<h5 id="org2366c86"><span class="section-number-5">3.1.3.5</span> Iterative Deepening Depth-first Search</h5>
<div class="outline-text-5" id="text-3-1-3-5">
<p>
Key idea is to gradually increase the depth limit: first 0, then
1, then 2&#x2026; until a goal is found.
</p>



<div class="figure">
<p><img src="images/ai/Problem-Solving/screenshot_2018-01-22_15-26-50.png" alt="screenshot_2018-01-22_15-26-50.png" />
</p>
</div>


<p>
\(N(IDS) = (d)b + (d-1)b^2 + \hdots + (1)b^d\), which gives a time
complexity of \(O(b^d)\)
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">performance</th>
<th scope="col" class="org-left">rating</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">completeness</td>
<td class="org-left">YES</td>
</tr>

<tr>
<td class="org-left">optimal</td>
<td class="org-left">NO (unless step cost is 1)</td>
</tr>

<tr>
<td class="org-left">time complexity</td>
<td class="org-left">\(O(b^d)\)</td>
</tr>

<tr>
<td class="org-left">space complexity</td>
<td class="org-left">\(O(b^d)\), \(O(m)\) if backtrack</td>
</tr>
</tbody>
</table>


<ol class="org-ol">
<li>BFS and IDS are complete if \(b\) is finite.</li>
<li>UCS is complete if \(b\) is finite and step cost is \(\ge \epsilon\).</li>
<li>BFS and IDS are optimal if all step costs are identical.</li>
</ol>
</div>
</div>
<div id="outline-container-orgfd81acf" class="outline-5">
<h5 id="orgfd81acf"><span class="section-number-5">3.1.3.6</span> Bidirectional Search</h5>
<div class="outline-text-5" id="text-3-1-3-6">
<p>
Conduct two simultaneous searches &#x2013; one forward from the initial
state, and the other backward from the goal. This is implemented by
replacing the goal test with a check to see whether the frontiers of
two searches intersect. This reduces the time ad space complexity to \(O(b^{d/2})\).
</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Jethro Kuan</p>
<p class="date">Created: 2018-01-22 Mon 15:36</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
